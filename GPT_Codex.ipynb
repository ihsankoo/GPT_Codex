{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## SQL Translate"],"metadata":{"id":"KuMB5xs8loWo"}},{"cell_type":"code","source":["!pip install --upgrade openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WduIsM2MmESY","outputId":"39b9849d-3597-48aa-c3e2-a5e4369d6bf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp (from openai)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m865.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["import openai\n","api_key = \"sk-...........................................NP\"\n","openai.api_key = api_key"],"metadata":{"id":"8yn1eXe9mKCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"### Microsoft SQL tables, with their properties:\n","#\n","# Employee(id, name, department_id)\n","# Department(id, name, address)\n","# Sales_amount(id, employee_id, amount, date)\n","#\n","### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\n","SELECT\"\"\""],"metadata":{"id":"cXZDa1FwTO2D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"Ewezmz6P00gn","outputId":"9aba5919-b212-4b5a-cea6-1e4077d30393"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'### Microsoft SQL tables, with their properties:\\n#\\n# Employee(id, name, department_id)\\n# Department(id, name, address)\\n# Sales_amount(id, employee_id, amount, date)\\n#\\n### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\\nSELECT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=150,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"#\", \";\"]\n",")\n","\n","# The \"temperature\" parameter in GPT models controls the randomness of the output. It is set between 0 and 2, where 0 is the most predictable and 2 is the most random. \n","# When the temperature is 0, GPT chooses the most probable answer each time. When the temperature parameter is 2, the randomness of the output increases and the quality \n","# of the output decreases. However, it is recommended to set the temperature value to around 0.8 max.\n","\n","# The \"top_p\" parameter in GPT models determines the ratio of the most likely next tokens to be considered when the model generates text. A higher value for this parameter \n","# results in more predictable and consistent text. For example, a top_p of 0.7 will produce more consistent and understandable text than a top_p of 0.3.\n","\n","# For positive values: The \"frequency penalty\" reduces the chance of a word being chosen again as its usage number increases, while the \"presence penalty\" reduces \n","# the chance of a word being selected again based on whether or not it has been used before. In other words, the \"presence penalty\" does not take into account how frequently\n","# a word is used, it only looks at whether or not it is present in the text.\n","\n","# For negative values: The \"frequency penalty\" increases the chance of a word being chosen again as its usage number increases, and the \"presence penalty\" increases \n","# the chance of a word being chosen again based on whether or not it has been used before.\n","\n","# Although the \"frequency penalty\" and \"presence penalty\" can take values between -2 and +2, it is recommended to use values between 0.1 and 1."],"metadata":{"id":"sJBduWlkltl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cx-QhwmmprU","outputId":"b804b2c8-2e9c-4b43-972a-fe097dca6953"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<OpenAIObject text_completion id=cmpl-7CRmeHCqWCRNOkwWj79akxDCmE610 at 0x7fed1dd63330> JSON: {\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"text\": \" e.name \\nFROM Employee e \\nINNER JOIN Sales_amount sa \\nON e.id = sa.employee_id \\nWHERE sa.date > DATEADD(month, -3, GETDATE()) \\nGROUP BY e.name \\nHAVING SUM(sa.amount) > 10000\"\n","    }\n","  ],\n","  \"created\": 1683201092,\n","  \"id\": \"cmpl-7CRmeHCqWCRNOkwWj79akxDCmE610\",\n","  \"model\": \"text-davinci-003\",\n","  \"object\": \"text_completion\",\n","  \"usage\": {\n","    \"completion_tokens\": 72,\n","    \"prompt_tokens\": 79,\n","    \"total_tokens\": 151\n","  }\n","}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["response[\"choices\"][0] # We are accessing a dictionary within \"choices\"."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0gDqpP3mqi0","outputId":"ecf24b5d-d132-43f4-d667-7831e8697fd6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<OpenAIObject at 0x7f9893f7c040> JSON: {\n","  \"finish_reason\": \"stop\",\n","  \"index\": 0,\n","  \"logprobs\": null,\n","  \"text\": \" e.name \\nFROM Employee e \\nINNER JOIN Sales_amount sa \\nON e.id = sa.employee_id \\nWHERE sa.date > DATE_SUB(CURDATE(), INTERVAL 3 MONTH) \\nGROUP BY e.name \\nHAVING SUM(sa.amount) > 10000\"\n","}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["print(\"SELECT\"+response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgR3ZneZmzzY","outputId":"ad1b1a21-5b60-46c7-a05c-0407709ee045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SELECT e.name \n","FROM Employee e \n","INNER JOIN Sales_amount sa \n","ON e.id = sa.employee_id \n","WHERE sa.date > DATE_SUB(CURDATE(), INTERVAL 3 MONTH) \n","GROUP BY e.name \n","HAVING SUM(sa.amount) > 10000\n"]}]},{"cell_type":"code","source":["prompt = \"\"\"### Microsoft SQL tables, with their properties:\n","#\n","# Employee(id, name, department_id)\n","# Department(id, name, address)\n","# Sales_amount(id, employee_id, amount, date)\n","#\n","### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\n","SELECT\"\"\""],"metadata":{"id":"Ox8ZjaEktq37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=150,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"#\", \";\"]\n",")\n","print(\"SELECT\"+response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdN3o0SqtrEx","outputId":"6f970f50-1519-47a0-cb13-6c39f535de97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SELECT e.name \n","FROM Employee e \n","INNER JOIN Sales_amount sa \n","ON e.id = sa.employee_id \n","WHERE sa.date > DATEADD(month, -3, GETDATE()) \n","GROUP BY e.name \n","HAVING SUM(sa.amount) > 10000\n"]}]},{"cell_type":"markdown","source":["#### With GPT-3.5"],"metadata":{"id":"uAsW9UTas7WT"}},{"cell_type":"code","source":["import openai\n","\n","res = openai.ChatCompletion.create(\n","          model=\"gpt-3.5-turbo\",\n","          messages=[\n","          {\"role\": \"system\", \"content\": \"You are a Microsoft SQL expert. Answer the questions asked to you in the most accurate way. Return only the query that was asked to you.\\\n","          Microsoft SQL tables, with their properties:\\\n","          Employee(id, name, department_id)\\\n","          Department(id, name, address)\\\n","          Sales_amount(id, employee_id, amount, date)\"},\n","          {\"role\": \"user\", \"content\": \"A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\"}\n","      ]\n","  )"],"metadata":{"id":"lFeTg8cWzKUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epr_b10V1I2E","outputId":"aa9fcba9-1e49-49e2-a6ce-434968261e0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<OpenAIObject chat.completion id=chatcmpl-7HUNQWCjLYqDWhy0Y9cftUYY5cEwj at 0x7f06c71d38d0> JSON: {\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"message\": {\n","        \"content\": \"```\\nSELECT e.name\\nFROM Employee e\\nINNER JOIN Sales_amount sa\\nON e.id = sa.employee_id\\nWHERE sa.date >= DATEADD(month, -3, GETDATE())\\nGROUP BY e.name\\nHAVING SUM(sa.amount) > 10000\\n```\",\n","        \"role\": \"assistant\"\n","      }\n","    }\n","  ],\n","  \"created\": 1684402700,\n","  \"id\": \"chatcmpl-7HUNQWCjLYqDWhy0Y9cftUYY5cEwj\",\n","  \"model\": \"gpt-3.5-turbo-0301\",\n","  \"object\": \"chat.completion\",\n","  \"usage\": {\n","    \"completion_tokens\": 55,\n","    \"prompt_tokens\": 105,\n","    \"total_tokens\": 160\n","  }\n","}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["print(res[\"choices\"][0][\"message\"][\"content\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fYLWK8V2GVQ","outputId":"e5050470-4ebf-49fa-c293-e7aab2be1515"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["```\n","SELECT e.name\n","FROM Employee e\n","INNER JOIN Sales_amount sa\n","ON e.id = sa.employee_id\n","WHERE sa.date >= DATEADD(month, -3, GETDATE())\n","GROUP BY e.name\n","HAVING SUM(sa.amount) > 10000\n","```\n"]}]},{"cell_type":"code","source":["def chatgpt(system, question):\n","\n","  import openai\n","\n","  res = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","          {\"role\": \"system\", \"content\": f\"{system}\"},\n","          {\"role\": \"user\", \"content\": f\"{question}\"}],\n","    temperature=0,\n","    top_p=1,\n","    max_tokens=500,\n","    presence_penalty=0,\n","    frequency_penalty=0,\n","\n","    )\n","\n","  return print(res['choices'][0][\"message\"][\"content\"])"],"metadata":{"id":"b9lVn9ops9ZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["system = \"\"\"You are a Microsoft SQL expert. Answer the questions asked to you in the most accurate way. Return only the query that was asked to you.\n","          Microsoft SQL tables, with their properties:\n","          Employee(id, name, department_id)\n","          Department(id, name, address)\n","          Sales_amount(id, employee_id, amount, date)\"\"\"\n","\n","question = \"A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPW-XM6w8c0W","outputId":"697cd021-a35e-4057-fa62-d81e6e697556"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["```\n","SELECT e.name\n","FROM Employee e\n","JOIN Sales_amount sa ON e.id = sa.employee_id\n","WHERE sa.date >= DATEADD(month, -3, GETDATE())\n","GROUP BY e.id, e.name\n","HAVING SUM(sa.amount) > 10000\n","```\n"]}]},{"cell_type":"markdown","source":["## Python to natural language"],"metadata":{"id":"9iX8HwOmBsbh"}},{"cell_type":"code","source":["prompt =\"\"\"# Python 3 \n","def remove_common_prefix(x, prefix, ws_prefix): \n","    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n","    if ws_prefix: \n","        # keep the single whitespace as prefix \n","        x[\"completion\"] = \" \" + x[\"completion\"] \n","return x \n","\n","# Explanation of what the code does\n","\n","#\"\"\""],"metadata":{"id":"XHl8-zG8B3IV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=500,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"#\"]\n",")\n","print(response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hm1gobQBumb","outputId":"6346204e-afba-48d9-c4b1-cc9db31c095b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This code removes a common prefix from a given string. The parameters x, prefix, and ws_prefix are passed into the function. The x parameter is a dataframe containing a column called \"completion\". The prefix parameter is the string that is to be removed from the \"completion\" column. The ws_prefix parameter is a boolean value that determines whether or not a single whitespace should be kept as a prefix. \n","\n","\n"]}]},{"cell_type":"code","source":["system = \"You are a python 3 expert. Answer the questions asked to you in the most accurate way.\"\n","\n","question = \"\"\"\n","def remove_common_prefix(x, prefix, ws_prefix): \n","    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n","    if ws_prefix: \n","        # keep the single whitespace as prefix \n","        x[\"completion\"] = \" \" + x[\"completion\"] \n","return x\n","Explanation of what the code does\"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ejnjHPuCPaf","outputId":"334162c2-0a6e-4efb-e483-14af3ddb314f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This code defines a function called `remove_common_prefix` that takes three arguments: `x`, `prefix`, and `ws_prefix`. The function removes the common prefix from the \"completion\" column of the input dataframe `x`. \n","\n","First, the function removes the prefix from the \"completion\" column by using the `str` method of pandas dataframe and slicing the string from the length of the prefix to the end of the string. \n","\n","If `ws_prefix` is True, the function adds a single whitespace as the new prefix to the \"completion\" column. \n","\n","Finally, the function returns the modified dataframe `x`.\n"]}]},{"cell_type":"markdown","source":["## Translate programming languages"],"metadata":{"id":"YbLgd1taENty"}},{"cell_type":"code","source":["prompt = \"\"\"##### Translate this code from R into Python3\n","### R\n","    \n","    set.seed(42)\n","    train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n","    X_train <- X[train_index, ]\n","    X_test <- X[-train_index, ]\n","    y_train <- y[train_index]\n","    y_test <- y[-train_index]\n","    \n","### Python3\"\"\""],"metadata":{"id":"-xz_XhhFE49J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=150,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"###\"]\n",")\n","print(response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kn4LI64-EPh4","outputId":"bba52800-ab77-4f5e-8878-406a9354081b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","    np.random.seed(42)\n","    train_index = np.random.choice(len(y), round(0.9*len(y)), replace=False)\n","    X_train = X[train_index]\n","    X_test = X[~train_index]\n","    y_train = y[train_index]\n","    y_test = y[~train_index]\n"]}]},{"cell_type":"code","source":["system = \"You are a python3 and R expert. Answer the questions asked to you in the most accurate way.\"\n","\n","question = \"\"\"\n","set.seed(42)\n","train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n","X_train <- X[train_index, ]\n","X_test <- X[-train_index, ]\n","y_train <- y[train_index]\n","y_test <- y[-train_index]\n","Translate this code from R into Python3\"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBKkT4pBFJft","outputId":"3248e043-c334-4718-f35d-193a1695eede"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","np.random.seed(42)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"]}]},{"cell_type":"markdown","source":["## Explain Code"],"metadata":{"id":"_f2Su2duJwI4"}},{"cell_type":"code","source":["prompt= \"\"\"\n","class Log:\n","    def __init__(self, path):\n","        dirname = os.path.dirname(path)\n","        os.makedirs(dirname, exist_ok=True)\n","        f = open(path, \"a+\")\n","\n","        # Check that the file is newline-terminated\n","        size = os.path.getsize(path)\n","        if size > 0:\n","            f.seek(size - 1)\n","            end = f.read(1)\n","            if end != \"\\n\":\n","                f.write(\"\\n\")\n","        self.f = f\n","        self.path = path\n","\n","    def log(self, event):\n","        event[\"_event_id\"] = str(uuid.uuid4())\n","        json.dump(event, self.f)\n","        self.f.write(\"\\n\")\n","\n","    def state(self):\n","        state = {\"complete\": set(), \"last\": None}\n","        for line in open(self.path):\n","            event = json.loads(line)\n","            if event[\"type\"] == \"submit\" and event[\"success\"]:\n","                state[\"complete\"].add(event[\"id\"])\n","                state[\"last\"] = event\n","        return state\n","\n","\\\"\\\"\\\"\n","Here's what the above class is doing, explained in a concise way:\n","1.\"\"\""],"metadata":{"id":"HdEhvfVEJulg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=300,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"\\\"\\\"\\\"\"]\n",")\n","print(\"1.\"+response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gui9qXQyJus6","outputId":"2f420320-a908-4f2b-f7e4-963cc2699720"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. The __init__ method creates a new file at the given path, and checks that it is newline-terminated.\n","2. The log method adds a new event to the log file, with a unique ID.\n","3. The state method reads the log file and returns a dictionary containing the set of completed tasks and the last successful event.\n","\n"]}]},{"cell_type":"code","source":["system = \"You are a python3 expert. explain the python codes asked to you in the most accurate way.\"\n","\n","question = \"\"\"\n","class Log:\n","    def __init__(self, path):\n","        dirname = os.path.dirname(path)\n","        os.makedirs(dirname, exist_ok=True)\n","        f = open(path, \"a+\")\n","\n","        # Check that the file is newline-terminated\n","        size = os.path.getsize(path)\n","        if size > 0:\n","            f.seek(size - 1)\n","            end = f.read(1)\n","            if end != \"\\n\":\n","                f.write(\"\\n\")\n","        self.f = f\n","        self.path = path\n","\n","    def log(self, event):\n","        event[\"_event_id\"] = str(uuid.uuid4())\n","        json.dump(event, self.f)\n","        self.f.write(\"\\n\")\n","\n","    def state(self):\n","        state = {\"complete\": set(), \"last\": None}\n","        for line in open(self.path):\n","            event = json.loads(line)\n","            if event[\"type\"] == \"submit\" and event[\"success\"]:\n","                state[\"complete\"].add(event[\"id\"])\n","                state[\"last\"] = event\n","        return state\n","explain above class\"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CChWc6iEKSgZ","outputId":"a6277ee4-cc58-45e6-85c1-1c7ef0b19055"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The above code defines a class called `Log`. The `__init__` method of the class takes a `path` argument which is the path to a log file. The method creates the directory for the log file if it doesn't exist and opens the file in append mode. It also checks if the file is newline-terminated and adds a newline character if it isn't. The `self.f` attribute is set to the opened file object and `self.path` is set to the path of the log file.\n","\n","The `log` method of the class takes an `event` argument which is a dictionary representing an event. The method adds a unique `_event_id` key to the event dictionary using the `uuid.uuid4()` method and then writes the event dictionary to the log file in JSON format using the `json.dump()` method. A newline character is also added to the end of the line.\n","\n","The `state` method of the class reads the log file line by line and parses each line as a JSON object. It then checks if the event type is \"submit\" and if the event was successful. If it was, the event ID is added to a set of completed events and the last event is updated to the current event. The method returns a dictionary with two keys: \"complete\" which is the set of completed event IDs and \"last\" which is the last event in the log file.\n"]}]},{"cell_type":"markdown","source":["## Python bug fixer"],"metadata":{"id":"KwPXWuXdLNWN"}},{"cell_type":"code","source":["prompt =\"\"\"\n","##### Fix bugs in the below function\n"," \n","### Buggy Python\n","import Random\n","a = random.randint(1,12)\n","b = random.randint(1,12)\n","for i in range(10):\n","    question = \"What is \"+a+\" x \"+b+\"? \"\n","    answer = input(question)\n","    if answer = a*b\n","        print (Well done!)\n","    else:\n","        print(\"No.\")\n","    \n","### Fixed Python\"\"\""],"metadata":{"id":"Qu7Bnm7lLSFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=300,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"###\"]\n",")\n","print(response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-_qgVCgLq90","outputId":"e23e9183-9e78-4adb-83b1-0d3a275476f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","import random\n","a = random.randint(1,12)\n","b = random.randint(1,12)\n","for i in range(10):\n","    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n","    answer = int(input(question))\n","    if answer == a*b:\n","        print (\"Well done!\")\n","    else:\n","        print(\"No.\")\n"]}]},{"cell_type":"code","source":["system = \"You are a python3 expert. fix bugs in the python codes asked to you in the most accurate way.\"\n","\n","question = \"\"\"\n","import Random\n","a = random.randint(1,12)\n","b = random.randint(1,12)\n","for i in range(10):\n","    question = \"What is \"+a+\" x \"+b+\"? \"\n","    answer = input(question)\n","    if answer = a*b\n","        print (Well done!)\n","    else:\n","        print(\"No.\")\"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OW2hy_wvL5x-","outputId":"a40ac1ed-695a-4911-d216-34535a961b4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are several errors in the code. Here's the corrected code:\n","\n","```python\n","import random\n","\n","a = random.randint(1, 12)\n","b = random.randint(1, 12)\n","\n","for i in range(10):\n","    question = \"What is \" + str(a) + \" x \" + str(b) + \"? \"\n","    answer = int(input(question))\n","    if answer == a * b:\n","        print(\"Well done!\")\n","    else:\n","        print(\"No.\")\n","```\n","\n","Changes made:\n","- `random` module was imported with a capital R, which is incorrect. It should be `import random`.\n","- The variables `a` and `b` were not converted to strings before concatenating with other strings. I added `str()` to convert them to strings.\n","- The `input()` function returns a string, so the `answer` variable needs to be converted to an integer using `int()`.\n","- The `if` statement had a syntax error. The comparison operator `==` was used instead of `=`. Also, the string \"Well done!\" was not enclosed in quotes.\n","- The `else` statement was missing quotes around the string \"No.\".\n"]}]},{"cell_type":"code","source":["system = \"You are a python3 expert. fix bugs in the python codes asked to you in the most accurate way. just return fixed python codes\"\n","\n","question = \"\"\"\n","import Random\n","a = random.randint(1,12)\n","b = random.randint(1,12)\n","for i in range(10):\n","    question = \"What is \"+a+\" x \"+b+\"? \"\n","    answer = input(question)\n","    if answer = a*b\n","        print (Well done!)\n","    else:\n","        print(\"No.\")\"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IoW38kA6Mhht","outputId":"1e43a84b-b8d3-44c9-a1a2-19cf2cacab40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["import random\n","a = random.randint(1,12)\n","b = random.randint(1,12)\n","for i in range(10):\n","    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n","    answer = int(input(question))\n","    if answer == a*b:\n","        print (\"Well done!\")\n","    else:\n","        print(\"No.\")\n"]}]},{"cell_type":"markdown","source":["## JavaScript to Python"],"metadata":{"id":"zMPzq6wUO_yX"}},{"cell_type":"code","source":["prompt=\"\"\"\n","#JavaScript to Python:\n","JavaScript: \n","dogs = [\"bill\", \"joe\", \"carl\"]\n","car = []\n","dogs.forEach((dog) {\n","    car.push(dog);\n","});\n","\n","Python:\"\"\""],"metadata":{"id":"JrZbsNwhPBfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=300,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0\n",")\n","print(response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onYk524ZPLVj","outputId":"70c103d8-4531-4c8c-b04d-795aeefb4dbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","dogs = [\"bill\", \"joe\", \"carl\"]\n","car = []\n","for dog in dogs:\n","    car.append(dog)\n"]}]},{"cell_type":"code","source":["system = \"You are a python3 and javascript expert. Translate this code from javascript into Python3 in the most accurate way.\"\n","\n","question = \"\"\"\n","dogs = [\"bill\", \"joe\", \"carl\"]\n","car = []\n","dogs.forEach((dog) {\n","    car.push(dog);\n","});\"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voq7UeqDPTgv","outputId":"b6da53da-6e0a-4906-c74a-07c8fe47463e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dogs = [\"bill\", \"joe\", \"carl\"]\n","car = []\n","for dog in dogs:\n","    car.append(dog)\n"]}]},{"cell_type":"markdown","source":["## Write a Python docstring"],"metadata":{"id":"z9uPvluDQaNp"}},{"cell_type":"code","source":["prompt=\"\"\"\n","# Python 3 \n","def remove_common_prefix(x, prefix, ws_prefix): \n","    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n","    if ws_prefix: \n","        # keep the single whitespace as prefix \n","        x[\"completion\"] = \" \" + x[\"completion\"] \n","return x \n","\n","# An elaborate, high quality docstring for the above function:\n","\"\\\"\\\"\\\"\"\n","\"\"\""],"metadata":{"id":"emIPUzTcQbi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openai\n","\n","response = openai.Completion.create(\n","  model=\"text-davinci-003\",\n","  prompt=prompt,\n","  temperature=0,\n","  max_tokens=150,\n","  top_p=1.0,\n","  frequency_penalty=0.0,\n","  presence_penalty=0.0,\n","  stop=[\"#\", \"\\\"\\\"\\\"\"]\n",")\n","print(response[\"choices\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Yb0MJ7nRSFq","outputId":"cee0f4fe-bef4-480f-b501-066117116b1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This function removes a common prefix from a given string.\n","\n","Parameters:\n","    x (str): The string to remove the prefix from.\n","    prefix (str): The prefix to remove from the string.\n","    ws_prefix (bool): Whether to keep a single whitespace as a prefix.\n","\n","Returns:\n","    x (str): The string with the prefix removed.\n","\n","Raises:\n","    ValueError: If the prefix is not found in the string.\n","\n"]}]},{"cell_type":"code","source":["system = \"You are a python3 expert. write high quality docstring for Python3 codes given to you the most accurate way.\"\n","\n","question = \"\"\"\n","def remove_common_prefix(x, prefix, ws_prefix): \n","    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n","    if ws_prefix: \n","        # keep the single whitespace as prefix \n","        x[\"completion\"] = \" \" + x[\"completion\"] \n","return x \"\"\"\n","\n","chatgpt(system, question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1ldkHllRfsz","outputId":"75829c19-1722-4638-e296-f08eae58f935"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\"\"\"\n","Removes a common prefix from a given string in a pandas DataFrame column.\n","\n","Args:\n","    x (pandas.DataFrame): A pandas DataFrame containing a column named \"completion\" that needs to be modified.\n","    prefix (str): The common prefix to be removed from the \"completion\" column.\n","    ws_prefix (bool): A boolean value indicating whether to keep a single whitespace as prefix after removing the common prefix.\n","\n","Returns:\n","    pandas.DataFrame: The modified pandas DataFrame with the common prefix removed from the \"completion\" column.\n","\n","Example:\n","    >>> df = pd.DataFrame({'completion': ['apple', 'apples', 'apricot']})\n","    >>> df = remove_common_prefix(df, 'ap', True)\n","    >>> print(df)\n","         completion\n","    0       ple\n","    1      ples\n","    2     ricot\n","\"\"\"\n"]}]},{"cell_type":"markdown","source":["## Edit Codes"],"metadata":{"id":"Kbk_PD6MTBzP"}},{"cell_type":"code","source":["def CodeEdit(input, instruction):\n","\n","  import openai\n","\n","  res = openai.Edit.create(\n","    model= \"code-davinci-edit-001\",\n","    input= f\"{input}\",\n","    instruction= f\"{instruction}\",\n","    temperature=0.0,\n","    top_p=1)\n","  return print(res[\"choices\"][0][\"text\"])"],"metadata":{"id":"lazXgBoUTEd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CodeEdit(input=\" \", instruction=\"Write a function in python that calculates fibonacci\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8T7_3Wo9TNvY","outputId":"b21e4bec-f4fa-4a0e-eb15-045b6b5fd592"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["def fibonacci(n):\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    else:\n","        return fibonacci(n-1) + fibonacci(n-2)\n","\n","print(fibonacci(9))\n","\n"]}]},{"cell_type":"code","source":["input = \"\"\"def fibonacci(n):\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    else:\n","        return fibonacci(n-1) + fibonacci(n-2)\n","\n","print(fibonacci(9))\"\"\"\n","CodeEdit(input=input, instruction=\"Add docstring\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbsF83t8TQxj","outputId":"92c48067-f048-4882-8618-b55ccca6ebfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["def fibonacci(n):\n","    \"\"\"\n","    Returns the nth number in the fibonacci sequence\n","    \"\"\"\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    else:\n","        return fibonacci(n-1) + fibonacci(n-2)\n","\n","print(fibonacci(9))\n","\n"]}]},{"cell_type":"code","source":["input = \"\"\"def fibonacci(n):\n","    \\\"\\\"\\\"\n","    Returns the nth number in the fibonacci sequence\n","    \\\"\\\"\\\"\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    else:\n","        return fibonacci(n-1) + fibonacci(n-2)\n","\n","print(fibonacci(9))\"\"\"\n","CodeEdit(input=input, instruction=\"Rename the function to fib\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nqrizhh0Tdt3","outputId":"9a144a4c-3371-4a67-888b-c8b14257b296"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["def fib(n):\n","    \"\"\"\n","    Returns the nth number in the fibonacci sequence\n","    \"\"\"\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    else:\n","        return fib(n-1) + fib(n-2)\n","\n","print(fib(9))\n","\n"]}]},{"cell_type":"code","source":["instruction=\"1 ile 100 arasındaki 3 ve 5'e bölünen sayıları bulan python3 kodunu yaz\"\n","CodeEdit(input=\" \", instruction=instruction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1IF6nE1ToUm","outputId":"22a30327-9647-42a5-ad03-132a2750e119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["for i in range(1,101):\n","    if i%3==0 and i%5==0:\n","        print(i)\n","\n"]}]},{"cell_type":"code","source":["instruction=\"\"\"Microsoft SQL tabloları:\n","\n","Employee(id, name, department_id)\n","Department(id, name, address)\n","Sales_amount(id, employee_id, amount, date)\n","\n","yukarıdaki tablolara göre son 5 ay içerisinde toplam olarak 10 bin tl satış yapan çalışanların isimlerini listeyen query'i yaz\"\"\"\n","CodeEdit(input=\" \", instruction=instruction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wbaf_CEUD3L","outputId":"32e95e20-82f6-4162-a978-3197ccf48b62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SELECT e.name\n","FROM Employee e\n","INNER JOIN Sales_amount s ON e.id = s.employee_id\n","WHERE s.date BETWEEN DATEADD(MONTH, -5, GETDATE()) AND GETDATE()\n","GROUP BY e.name\n","HAVING SUM(s.amount) >= 10000\n","\n"]}]},{"cell_type":"code","source":["input=\"\"\"dogs = [\"bill\", \"joe\", \"carl\"]\n","car = []\n","dogs.forEach((dog) {\n","    car.push(dog);\n","});\"\"\"\n","\n","instruction= \"python'a dönüştür\"\n","\n","CodeEdit(input=input, instruction=instruction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMjE2SBmUzcu","outputId":"3235679b-f4b8-4699-d4a7-8569f9491f38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dogs = [\"bill\", \"joe\", \"carl\"];\n","car = [];\n","for dog in dogs:\n","    car.append(dog);\n","\n"]}]},{"cell_type":"code","source":["input = \"\"\"\n","set.seed(42)\n","train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n","X_train <- X[train_index, ]\n","X_test <- X[-train_index, ]\n","y_train <- y[train_index]\n","y_test <- y[-train_index]\"\"\"\n","\n","instruction= \"R'dan python'a dönüştür.\"\n","\n","CodeEdit(input=input, instruction=instruction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7qxhOCNa0Pb","outputId":"6054c52a-92e7-4c3b-b296-b7f0c1e25920"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv(\"data.csv\")\n","\n","X = df.drop([\"y\"], axis=1)\n","y = df[\"y\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n"]}]},{"cell_type":"code","source":["#"],"metadata":{"id":"wcFUc14ex8rL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Count of tokens for gpt-3.5-turbo-0301"],"metadata":{"id":"IOsuQXQLx90U"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRr_XkQ9cVPH","outputId":"8e9c2302-d8dd-41b2-f648-bd958512cb0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]}]},{"cell_type":"code","source":["def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n","  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n","  import tiktoken\n","  try:\n","      encoding = tiktoken.encoding_for_model(model)\n","  except KeyError:\n","      encoding = tiktoken.get_encoding(\"cl100k_base\")\n","  if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n","      num_tokens = 0\n","      for message in messages:\n","          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n","          for key, value in message.items():\n","              num_tokens += len(encoding.encode(value))\n","              if key == \"name\":  # if there's a name, the role is omitted\n","                  num_tokens += -1  # role is always required and always 1 token\n","      num_tokens += 2  # every reply is primed with <im_start>assistant\n","      return num_tokens\n","  else:\n","      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n","  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"],"metadata":{"id":"SUlq_cqRx7MN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages = [\n","  {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\"},\n","  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"New synergies will help drive top-line growth.\"},\n","  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Things working well together will increase revenue.\"},\n","  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n","  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n","  {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n","]\n","\n","model = \"gpt-3.5-turbo-0301\"\n","\n","print(f\"{num_tokens_from_messages(messages, model)} prompt tokens counted.\")\n","# Should show ~126 total_tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4007c33e-d022-4ca0-d10e-ae4e0a9dbad1","id":"iDQMWSZ-x7MO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["126 prompt tokens counted.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SgfDH9FlxxGJ"},"execution_count":null,"outputs":[]}]}